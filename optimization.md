## Mini batch gradient descent

Split training set into mini batches and use one mini batch in one gradient descent iteration.

1 epoch = 1 pass through the entire training set
